{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Create a  Python Google Colab Persistence Virtual Environment\n",
        "\n",
        "*  ***Ephemeral nature of Colab:***\n",
        "\n",
        "The \"ephemeral nature\" of Google Colab means that its runtime environment is temporary and will be automatically deleted when not actively in use. Essentially, any data or changes you make within a Colab session are not permanently stored unless explicitly saved, making it ideal for quick experiments and prototyping while requiring careful management of data persistence for longer-term projects.\n",
        "\n",
        "*  ***Workarounds for persistence:***\n",
        "\n",
        "To maintain changes across sessions, store the virtual environment and its dependencies outside the Colab runtime, such as on Google Drive or JuiceFS, based on the reference for the cloud-based high-performance distributed file system and its limitations."
      ],
      "metadata": {
        "id": "X3MNoPFM01CP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JuiceFS vs. Google Cloud Storage\n",
        "\n",
        "Choosing between JuiceFS and Google Cloud Storage depends on specific needs. Still, if a file system with POSIX compatibility, high performance for frequent file access, and seamless integration with existing applications is required, JuiceFS is generally considered the better option. At the same time, Google Cloud Storage excels in large-scale, low-cost data storage with high durability, particularly for infrequently accessed data.\n",
        "\n",
        "Users often use Google Drive to store files persistently in Colab. However, Google Drive has usage restrictions, such as total upload bandwidth and a maximum file count. As an open-source distributed file system, JuiceFS has no limitations and is cost-effective because it flexibly organizes resources.\n",
        "\n",
        "[How to Persist Data in Google Colab Using JuiceFS](https://juicefs.com/en/blog/usage-tips/colab-persist-data)\n",
        "\n",
        "\n",
        "JuiceFS is a cloud-native, high-performance distributed file system licensed under Apache 2.0. It is completely POSIX compatible and supports various access methods, including FUSE POSIX, HDFS, S3, the Kubernetes CSI Driver, and WebDAV.\n",
        "\n",
        "In Colab, you can mount JuiceFS using the FUSE POSIX method as a background daemon.\n"
      ],
      "metadata": {
        "id": "tmvoZDDCM6eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Mount Google Drive"
      ],
      "metadata": {
        "id": "QBsZiNRMlUwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CGG4Slafzjye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Create an AI development virtual environment (**python_ai_env**) for the Python programming language"
      ],
      "metadata": {
        "id": "ex89Ikmu00B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!pip install virtualenv --upgrade\n",
        "!virtualenv /content/drive/MyDrive/python_ai_env\n",
        "%cd /content/drive/MyDrive/python_ai_env\n",
        "!python -m venv python_ai_env"
      ],
      "metadata": {
        "id": "4NVN04f01Vyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Activate the Python Virtual Environment"
      ],
      "metadata": {
        "id": "GVPhsm_q00J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/drive/MyDrive/my_colab_env/bin/activate"
      ],
      "metadata": {
        "id": "3RLiD8gs3VFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Create the file: In our project's root directory, create a file named requirements.txt"
      ],
      "metadata": {
        "id": "X5aOp8ZD00Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/requirements.txt', 'w') as f:\n",
        "  f.write('requirements.txt!')"
      ],
      "metadata": {
        "id": "iQ-0ilRR84Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Add dependencies list the packages you need, one per line, in the requirements.txt. We can specify versions if needed:"
      ],
      "metadata": {
        "id": "HDZ6BCxj00Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('requirements.txt', 'w') as f:\n",
        "     f.write('altair\\numpy\\nscikit-learn\\nmatplotlib\\pandas\\spacy\\-U scikit-learn\\xgboost\\scispacy\\pysoundfile')"
      ],
      "metadata": {
        "id": "4Jaka89n9LiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Install the dependencies in the requirements.txt:"
      ],
      "metadata": {
        "id": "M5FQ8AIf00SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "9XoxNbhw9bAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7: Install more libraries are need and not in requirements.txt:"
      ],
      "metadata": {
        "id": "06ngy5Ec00U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install altair\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install spacy\n",
        "!pip install -U scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install scispacy\n",
        "!pip install pysoundfile\n",
        "!pip install libav-tools -y\n",
        "!pip install zip\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-io\n",
        "!pip install matplotlib\n",
        "!pip install transformers\n",
        "!pip install scispacy"
      ],
      "metadata": {
        "id": "0hh85G219zpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step 8: Upgrade Python virtual environment packages:"
      ],
      "metadata": {
        "id": "V2drEQhI94BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn --upgrade\n",
        "!pip install xgboost --upgrade"
      ],
      "metadata": {
        "id": "oDmUeI5V9-bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 9: Re-accessing the Python virtual environment packages:"
      ],
      "metadata": {
        "id": "jxe1NjH_00Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LjHzcW-Z-Ghf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 10: Re-activate the Python virtual environment packages."
      ],
      "metadata": {
        "id": "p-8ITF1p00al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/drive/MyDrive/my_colab_env/bin/activate"
      ],
      "metadata": {
        "id": "gHZT6GI4Bhjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 11: Import and use the Python packages forthe first time"
      ],
      "metadata": {
        "id": "B7PE-nD7BsfZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_0UXVHPyZ7S"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import altair as alt\n",
        "import pickle\n",
        "import string\n",
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "import IPython\n",
        "import librosa\n",
        "import librosa.display\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import os\n",
        "import glob\n",
        "import threading\n",
        "import altair as alt\n",
        "import pylab\n",
        "import gc\n",
        "import scispacy\n",
        "import soundfile as sf\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "import csv\n",
        "import google.colab.files\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
        "from nltk.util import ngrams\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from PIL import Image\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.ensemble import *\n",
        "from sklearn.neighbors import *\n",
        "from sklearn.tree import *\n",
        "from sklearn.calibration import *\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.multiclass import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from collections import Counter\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier  # Simple deep learning (multi-layer perceptron)\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from fastai.text import *\n",
        "from fastai.vision import *\n",
        "from spacy import displacy\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBClassifier\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 12: Access the Google Colab Persistence Virtual Environmentmodules or packages with sys.path:\n"
      ],
      "metadata": {
        "id": "fx75PcmVVLmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/my_colab_env/lib/python3.10/site-packages\")"
      ],
      "metadata": {
        "id": "itp59JKnV2zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workflow After Disconnect\n",
        "\n",
        "1. Mount Google Drive:\n",
        "from google.colab import drive\n",
        "   drive.mount('/content/drive')\n",
        "2. Activate Virtual Environment:\n",
        "!source '/content/drive/My Drive/my_env/bin/activate'\n",
        "\n",
        "**Activation is Key**: Activating the virtual environment is essential. This tells Colab to use the Python interpreter and packages within your environment instead of the default Colab environment.\n",
        "\n",
        "**Package Updates**: If you need to update a package or install new ones, make sure you do so within the activated virtual environment. This ensures the changes are saved to your Google Drive.\n",
        "\n",
        "In summary, by using a virtual environment on Google Drive, you create a persistent space for your packages. You only need to activate the environment after a disconnect, and the packages you installed previously will be readily available. This saves you time and effort in reinstalling packages every time you work on your project in Colab."
      ],
      "metadata": {
        "id": "yB2BsITXlhnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do I need to install the packages I installed in the Google Drive virtual environment after the disconnect for Google Colab?\n",
        "\n",
        "1. Virtual Environment Isolation: A virtual environment isolates the packages for your project. When you install packages inside the environment, they are stored within the environment's directory on your Google Drive, not in the temporary Colab runtime.\n",
        "\n",
        "2. Google Drive Persistence: Google Drive is persistent storage. Even if your Colab runtime disconnects, the contents of your Google Drive, including your virtual environment and its installed packages, remain unchanged."
      ],
      "metadata": {
        "id": "EgXozcROlDEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to import the package from my virtual environment to my google colab?"
      ],
      "metadata": {
        "id": "XvIiA_wfsE4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In order to find the library installed on the virtual environment we should add the path of the virtual environmentsite-packages to colab system path."
      ],
      "metadata": {
        "id": "SpHq-XAgWewh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# added the path of virtual environment packages to the system path.\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ai_env/lib/python3.10/site-packages')"
      ],
      "metadata": {
        "id": "N-BRmNh5WeWF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}